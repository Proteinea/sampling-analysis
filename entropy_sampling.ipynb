{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3 threads\n",
      "Read 500 sequences (type: Protein) from msa_input.fasta\n",
      "Calculating pairwise ktuple-distances...\n",
      "Ktuple-distance calculation progress done. CPU time: 15.14u 0.00s 00:00:15.14 Elapsed: 00:00:05\n",
      "Guide-tree computation done.\n",
      "Progressive alignment progress done. CPU time: 13.91u 0.10s 00:00:14.01 Elapsed: 00:00:08\n",
      "Alignment written to _temp_msa_output.fasta\n"
     ]
    }
   ],
   "source": [
    "from stateval.src.configs import MSAConfig\n",
    "from stateval.src.msa import Msa \n",
    "from stateval.src.sh_entropies import ShannonEntropies \n",
    "from stat_eval_utils import fasta2dict\n",
    "\n",
    "\n",
    "sequences = fasta2dict(\"./mdh_train_sample.fasta\")\n",
    "sequences = {id: seq for id, seq in zip(sequences[\"ID\"], sequences[\"Seq\"])}\n",
    "\n",
    "msa = Msa(MSAConfig(max_gap_ratio=0.8))\n",
    "aligned_seqs = msa.align(sequences)\n",
    "se = ShannonEntropies()\n",
    "entropies = se.calculate_entropies(aligned_seqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(v) for v in sequences.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "loading configuration file ./output_mhd/checkpoint-4800/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"./output_mhd/checkpoint-4800\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 1280,\n",
      "  \"n_head\": 20,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 36,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.34.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\n",
      "loading weights file ./output_mhd/checkpoint-4800/pytorch_model.bin\n",
      "Instantiating GPT2LMHeadModel model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0\n",
      "}\n",
      "\n",
      "Detected 8-bit loading: activating 8-bit loading for this model\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./output_mhd/checkpoint-4800.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading configuration file ./output_mhd/checkpoint-4800/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0\n",
      "}\n",
      "\n",
      "The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import yaml\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "with open('generation_config.yml', 'r') as file:\n",
    "    config  = yaml.safe_load(file)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config[\"model_checkpoint_path\"])\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # Add a padding token\n",
    "model = AutoModelForCausalLM.from_pretrained(config[\"model_checkpoint_path\"], device_map=\"auto\", load_in_8bit=True)\n",
    "model.to_bettertransformer()\n",
    "model.config.max_length = 512  #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.generation.logits_process import LogitsProcessor\n",
    "from typing import List\n",
    "class LogitEntropyProcessor(LogitsProcessor):\n",
    "    \n",
    "    def __init__(self, segments_indicies:List[int], temps:List[float], *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        assert len(temps) >= 1\n",
    "        self.temps = temps\n",
    "        self.segments_indicies = segments_indicies\n",
    "        self.temp_index = 0\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
    "         \n",
    "        scores = scores/ self.temps[self.temp_index]\n",
    "\n",
    "        if input_ids.shape[1]+1 > self.segments_indicies[self.temp_index] and self.temp_index +1 < len(self.temps):\n",
    "            self.temp_index += 1\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9378,\n",
       " 0.96915,\n",
       " 0.9507000000000001,\n",
       " 0.9848250000000001,\n",
       " 1.0359,\n",
       " 1.06935,\n",
       " 1.1604]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "n_segments = 7\n",
    "indicies = np.linspace(0, len(entropies), n_segments+1).astype(int)\n",
    "entropies_median = [np.median(entropies[indicies[i]: indicies[i+1]]) for i in range(n_segments)]\n",
    "temps = [0.3+ v* 1.5 for v in entropies_median] # 0.3 as a base temp in case the entropy is too low \n",
    "temps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  2%|▏         | 1/63 [00:09<09:46,  9.45s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  3%|▎         | 2/63 [00:19<10:00,  9.85s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  5%|▍         | 3/63 [00:29<09:51,  9.86s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  6%|▋         | 4/63 [00:39<09:34,  9.75s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "  8%|▊         | 5/63 [00:48<09:27,  9.79s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 10%|▉         | 6/63 [00:58<09:16,  9.77s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 11%|█         | 7/63 [01:08<09:12,  9.86s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 13%|█▎        | 8/63 [01:18<09:01,  9.85s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 14%|█▍        | 9/63 [01:28<08:47,  9.76s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 16%|█▌        | 10/63 [01:37<08:37,  9.77s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 17%|█▋        | 11/63 [01:47<08:25,  9.73s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 19%|█▉        | 12/63 [01:57<08:17,  9.76s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 21%|██        | 13/63 [02:07<08:09,  9.79s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 22%|██▏       | 14/63 [02:16<07:59,  9.78s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 24%|██▍       | 15/63 [02:26<07:46,  9.71s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 25%|██▌       | 16/63 [02:36<07:36,  9.72s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 27%|██▋       | 17/63 [02:45<07:26,  9.71s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 29%|██▊       | 18/63 [02:55<07:18,  9.74s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 30%|███       | 19/63 [03:05<07:07,  9.71s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 32%|███▏      | 20/63 [03:15<06:57,  9.72s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 33%|███▎      | 21/63 [03:24<06:47,  9.70s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 35%|███▍      | 22/63 [03:34<06:38,  9.72s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 37%|███▋      | 23/63 [03:44<06:28,  9.70s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 38%|███▊      | 24/63 [03:54<06:20,  9.77s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 40%|███▉      | 25/63 [04:03<06:12,  9.79s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 41%|████▏     | 26/63 [04:13<06:04,  9.86s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 43%|████▎     | 27/63 [04:23<05:54,  9.86s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 44%|████▍     | 28/63 [04:33<05:44,  9.84s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 46%|████▌     | 29/63 [04:43<05:31,  9.75s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 48%|████▊     | 30/63 [04:52<05:20,  9.71s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 49%|████▉     | 31/63 [05:02<05:10,  9.72s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 51%|█████     | 32/63 [05:12<05:02,  9.74s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 52%|█████▏    | 33/63 [05:21<04:50,  9.67s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 54%|█████▍    | 34/63 [05:31<04:42,  9.74s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 56%|█████▌    | 35/63 [05:41<04:33,  9.79s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 57%|█████▋    | 36/63 [05:51<04:22,  9.72s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 59%|█████▊    | 37/63 [06:00<04:12,  9.70s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 60%|██████    | 38/63 [06:10<04:01,  9.67s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 62%|██████▏   | 39/63 [06:20<03:51,  9.65s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 63%|██████▎   | 40/63 [06:30<03:45,  9.81s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 65%|██████▌   | 41/63 [06:39<03:34,  9.75s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 67%|██████▋   | 42/63 [06:49<03:23,  9.71s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 68%|██████▊   | 43/63 [06:59<03:14,  9.72s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 70%|██████▉   | 44/63 [07:08<03:03,  9.68s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 71%|███████▏  | 45/63 [07:18<02:53,  9.66s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 73%|███████▎  | 46/63 [07:28<02:44,  9.69s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 75%|███████▍  | 47/63 [07:37<02:34,  9.68s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 76%|███████▌  | 48/63 [07:47<02:25,  9.69s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 78%|███████▊  | 49/63 [07:57<02:16,  9.77s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 79%|███████▉  | 50/63 [08:07<02:07,  9.82s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 81%|████████  | 51/63 [08:17<01:57,  9.76s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 83%|████████▎ | 52/63 [08:27<01:48,  9.87s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 84%|████████▍ | 53/63 [08:37<01:38,  9.86s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 86%|████████▌ | 54/63 [08:46<01:28,  9.80s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 87%|████████▋ | 55/63 [08:56<01:19,  9.94s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 89%|████████▉ | 56/63 [09:06<01:09,  9.92s/it]Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"max_length\": 512\n",
      "}\n",
      "\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 89%|████████▉ | 56/63 [09:41<01:12, 10.38s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Generate multiple prompt\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 22\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msequence_prompt_index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLogitsProcessorList\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLogitEntropyProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegments_indicies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicies\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# num_return_sequences=5\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m generated_output \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[1;32m     32\u001b[0m     generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(generated_output, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1606\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1590\u001b[0m         input_ids,\n\u001b[1;32m   1591\u001b[0m         assistant_model\u001b[38;5;241m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1603\u001b[0m     )\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1605\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2454\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2454\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2457\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2458\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2462\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1076\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1076\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1091\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:900\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    890\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    891\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    892\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    897\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    898\u001b[0m     )\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 900\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:390\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    388\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    389\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 390\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    399\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optimum/bettertransformer/models/decoder_models.py:98\u001b[0m, in \u001b[0;36mGPT2AttentionLayerBetterTransformer.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:312\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    310\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m encoder_attention_mask\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m     query, key, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_size, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    314\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_heads(query, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    315\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_heads(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:441\u001b[0m, in \u001b[0;36mLinear8bitLt.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m x\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 441\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mhas_fp16_weights:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mCB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mCxB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;66;03m# we converted 8-bit row major to turing/ampere format in the first inference pass\u001b[39;00m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# we no longer need the row-major weight\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:563\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(A, B, out, state, threshold, bias)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    562\u001b[0m     state\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m threshold\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMatMul8bitLt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:401\u001b[0m, in \u001b[0;36mMatMul8bitLt.forward\u001b[0;34m(ctx, A, B, out, bias, state)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_igemmlt:\n\u001b[1;32m    400\u001b[0m     C32A, SA \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mtransform(CA, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 401\u001b[0m     out32, Sout32 \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43migemmlt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC32A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCxB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m bias\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# we apply the fused bias here\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmm_dequant(out32, Sout32, SCA, state\u001b[38;5;241m.\u001b[39mSCB, bias\u001b[38;5;241m=\u001b[39mbias)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/functional.py:1723\u001b[0m, in \u001b[0;36migemmlt\u001b[0;34m(A, B, SA, SB, out, Sout, dtype)\u001b[0m\n\u001b[1;32m   1720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mtuple\u001b[39m(shapeA[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m [shapeB[\u001b[38;5;241m0\u001b[39m]]), device\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dimsA \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1723\u001b[0m     out, Sout \u001b[38;5;241m=\u001b[39m \u001b[43mget_transform_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapeA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapeB\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcol32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dimsA \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1727\u001b[0m     out, Sout \u001b[38;5;241m=\u001b[39m get_transform_buffer(\n\u001b[1;32m   1728\u001b[0m         (shapeA[\u001b[38;5;241m0\u001b[39m], shapeA[\u001b[38;5;241m1\u001b[39m], shapeB[\u001b[38;5;241m0\u001b[39m]), dtype, A\u001b[38;5;241m.\u001b[39mdevice, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol32\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1729\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/functional.py:461\u001b[0m, in \u001b[0;36mget_transform_buffer\u001b[0;34m(shape, dtype, device, to_order, from_order, transpose)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m to_order \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# blocks of 32 columns (padded)\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m \u001b[38;5;241m*\u001b[39m ((cols \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m31\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minit_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, state\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m to_order \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol_turing\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# blocks of 32 columns and 8 rows\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m \u001b[38;5;241m*\u001b[39m ((cols \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m31\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers.generation import LogitsProcessorList\n",
    "device = \"cuda\"\n",
    "generated_sequences = []\n",
    "batch_size = 8\n",
    "seqs = fasta2dict(\"./mdh_train_sample.fasta\")[\"Seq\"]\n",
    "for batch_idx in tqdm(range(0, len(sequences), batch_size)):\n",
    "        inputs = tokenizer.batch_encode_plus(\n",
    "            seqs[batch_idx:batch_idx+batch_size],\n",
    "            padding=\"longest\",\n",
    "            truncation=True,\n",
    "            max_length=512,  # Set the maximum length to 512\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        input_ids = inputs.input_ids\n",
    "        attention_mask = inputs.attention_mask\n",
    "        prompt = input_ids[:, :config[\"sequence_prompt_index\"]]\n",
    "        # Generate multiple prompt\n",
    "        with torch.no_grad():\n",
    "\n",
    "                outputs = model.generate(\n",
    "                    prompt,\n",
    "                    attention_mask=attention_mask[:, :config[\"sequence_prompt_index\"]],\n",
    "                    eos_token_id=0,\n",
    "                    max_length=512,\n",
    "                    logits_processor=LogitsProcessorList([LogitEntropyProcessor(segments_indicies=indicies[1:], temps=temps)]),\n",
    "                    use_cache=True\n",
    "                    \n",
    "                    # num_return_sequences=5\n",
    "                )\n",
    "        for generated_output in outputs:\n",
    "            generated_text = tokenizer.decode(generated_output, skip_special_tokens=True)\n",
    "            generated_text = generated_text.replace(\"|endoftext|>\", \"\")  # Remove the header\n",
    "            generated_sequences.append(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
       "         30., 282., 173.,   5.,   3.,   2.,   0.,   2.,   1.]),\n",
       " array([126. , 141.2, 156.4, 171.6, 186.8, 202. , 217.2, 232.4, 247.6,\n",
       "        262.8, 278. , 293.2, 308.4, 323.6, 338.8, 354. , 369.2, 384.4,\n",
       "        399.6, 414.8, 430. ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfzElEQVR4nO3de2yV9eHH8U/vgnBOLaU9bSh3FBgFEVg50zG2Nr3QMZldMrBTdAQCa41YRahzeNmyOmMm0ylk2QIzgelcBCcqsxYoEgtCR8NF7YTUFQendTQ9p4VRKP3+/vDHsx3uhR7Ot+37lTxJz/N8z9Pv+eaBvnMubYQxxggAAMAikeGeAAAAwLkIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWiQ73BK5GR0eHjhw5ov79+ysiIiLc0wEAAFfAGKOWlhalpqYqMvLSz5F0y0A5cuSI0tLSwj0NAABwFQ4fPqxBgwZdcky3DJT+/ftL+uoBulyuMM8GAABciUAgoLS0NOfn+KV0y0A5+7KOy+UiUAAA6Gau5O0ZvEkWAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWiQ73BACgJxi67O2QnfvzZ/JDdm7AVjyDAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDqdCpSysjJNmTJF/fv3V1JSkmbNmqXa2tqgMdOnT1dERETQtnDhwqAx9fX1ys/PV9++fZWUlKQlS5aovb392h8NAADoEaI7M7iyslJFRUWaMmWK2tvb9dhjjyk7O1sff/yxbrzxRmfc/Pnz9fTTTzu3+/bt63x95swZ5efny+Px6MMPP9TRo0d17733KiYmRr/85S+74CEBAIDurlOBsmnTpqDba9asUVJSkqqrqzVt2jRnf9++feXxeC54jvfee08ff/yx3n//fSUnJ+vWW2/Vz3/+cy1dulRPPvmkYmNjr+JhAACAnuSa3oPi9/slSQkJCUH7165dq8TERI0bN06lpaU6ceKEc6yqqkrp6elKTk529uXk5CgQCOjAgQMX/D5tbW0KBAJBGwAA6Lk69QzK/+ro6NDixYt1++23a9y4cc7+u+++W0OGDFFqaqr27t2rpUuXqra2Vm+88YYkyefzBcWJJOe2z+e74PcqKyvTU089dbVTBQAA3cxVB0pRUZH279+v7du3B+1fsGCB83V6erpSUlKUmZmpQ4cOacSIEVf1vUpLS1VSUuLcDgQCSktLu7qJAwAA613VSzzFxcXauHGjtmzZokGDBl1ybEZGhiTp4MGDkiSPx6OGhoagMWdvX+x9K3FxcXK5XEEbAADouToVKMYYFRcXa/369dq8ebOGDRt22fvU1NRIklJSUiRJXq9X+/btU2NjozOmvLxcLpdLY8eO7cx0AABAD9Wpl3iKioq0bt06vfnmm+rfv7/znhG3260+ffro0KFDWrdunWbMmKEBAwZo7969euihhzRt2jSNHz9ekpSdna2xY8fqnnvu0bPPPiufz6fHH39cRUVFiouL6/pHCAAAup1OPYOycuVK+f1+TZ8+XSkpKc722muvSZJiY2P1/vvvKzs7W6NHj9bDDz+sgoICvfXWW845oqKitHHjRkVFRcnr9epHP/qR7r333qDfmwIAAHq3Tj2DYoy55PG0tDRVVlZe9jxDhgzRO++805lvDQAAehH+Fg8AALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOt0KlDKyso0ZcoU9e/fX0lJSZo1a5Zqa2uDxpw8eVJFRUUaMGCA+vXrp4KCAjU0NASNqa+vV35+vvr27aukpCQtWbJE7e3t1/5oAABAj9CpQKmsrFRRUZF27Nih8vJynT59WtnZ2Tp+/Lgz5qGHHtJbb72l119/XZWVlTpy5Ijuuusu5/iZM2eUn5+vU6dO6cMPP9Qf//hHrVmzRsuXL++6RwUAALq1CGOMudo7f/nll0pKSlJlZaWmTZsmv9+vgQMHat26dfrBD34gSfr00081ZswYVVVVaerUqXr33Xf13e9+V0eOHFFycrIkadWqVVq6dKm+/PJLxcbGXvb7BgIBud1u+f1+uVyuq50+AHSZocveDtm5P38mP2TnBq6nzvz8vqb3oPj9fklSQkKCJKm6ulqnT59WVlaWM2b06NEaPHiwqqqqJElVVVVKT0934kSScnJyFAgEdODAgWuZDgAA6CGir/aOHR0dWrx4sW6//XaNGzdOkuTz+RQbG6v4+PigscnJyfL5fM6Y/42Ts8fPHruQtrY2tbW1ObcDgcDVThsAAHQDV/0MSlFRkfbv369XX321K+dzQWVlZXK73c6WlpYW8u8JAADC56oCpbi4WBs3btSWLVs0aNAgZ7/H49GpU6fU3NwcNL6hoUEej8cZc+6nes7ePjvmXKWlpfL7/c52+PDhq5k2AADoJjoVKMYYFRcXa/369dq8ebOGDRsWdHzSpEmKiYlRRUWFs6+2tlb19fXyer2SJK/Xq3379qmxsdEZU15eLpfLpbFjx17w+8bFxcnlcgVtAACg5+rUe1CKioq0bt06vfnmm+rfv7/znhG3260+ffrI7XZr3rx5KikpUUJCglwulx544AF5vV5NnTpVkpSdna2xY8fqnnvu0bPPPiufz6fHH39cRUVFiouL6/pHCAAAup1OBcrKlSslSdOnTw/av3r1at13332SpOeff16RkZEqKChQW1ubcnJy9PLLLztjo6KitHHjRi1atEher1c33nij5s6dq6effvraHgkAAOgxrun3oIQLvwcFgG34PSjA5V2334MCAAAQCgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsEx3uCQAALm3osrdDct7Pn8kPyXmBrsAzKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOt0OlC2bdummTNnKjU1VREREdqwYUPQ8fvuu08RERFBW25ubtCYpqYmFRYWyuVyKT4+XvPmzVNra+s1PRAAANBzdDpQjh8/rgkTJuill1666Jjc3FwdPXrU2f70pz8FHS8sLNSBAwdUXl6ujRs3atu2bVqwYEHnZw8AAHqk6M7eIS8vT3l5eZccExcXJ4/Hc8Fjn3zyiTZt2qRdu3Zp8uTJkqQXX3xRM2bM0HPPPafU1NTOTgkAAPQwIXkPytatW5WUlKRbbrlFixYt0rFjx5xjVVVVio+Pd+JEkrKyshQZGamdO3de8HxtbW0KBAJBGwAA6Lm6PFByc3P1yiuvqKKiQr/61a9UWVmpvLw8nTlzRpLk8/mUlJQUdJ/o6GglJCTI5/Nd8JxlZWVyu93OlpaW1tXTBgAAFun0SzyXM3v2bOfr9PR0jR8/XiNGjNDWrVuVmZl5VecsLS1VSUmJczsQCBApAAD0YCH/mPHw4cOVmJiogwcPSpI8Ho8aGxuDxrS3t6upqemi71uJi4uTy+UK2gAAQM8V8kD54osvdOzYMaWkpEiSvF6vmpubVV1d7YzZvHmzOjo6lJGREerpAACAbqDTL/G0trY6z4ZIUl1dnWpqapSQkKCEhAQ99dRTKigokMfj0aFDh/Too49q5MiRysnJkSSNGTNGubm5mj9/vlatWqXTp0+ruLhYs2fP5hM8AABA0lU8g7J7925NnDhREydOlCSVlJRo4sSJWr58uaKiorR3715973vf080336x58+Zp0qRJ+uCDDxQXF+ecY+3atRo9erQyMzM1Y8YM3XHHHfrd737XdY8KAAB0a51+BmX69Okyxlz0+N/+9rfLniMhIUHr1q3r7LcGAAC9BH+LBwAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdTodKNu2bdPMmTOVmpqqiIgIbdiwIei4MUbLly9XSkqK+vTpo6ysLH322WdBY5qamlRYWCiXy6X4+HjNmzdPra2t1/RAAABAz9HpQDl+/LgmTJigl1566YLHn332Wb3wwgtatWqVdu7cqRtvvFE5OTk6efKkM6awsFAHDhxQeXm5Nm7cqG3btmnBggVX/ygAAECPEt3ZO+Tl5SkvL++Cx4wxWrFihR5//HHdeeedkqRXXnlFycnJ2rBhg2bPnq1PPvlEmzZt0q5duzR58mRJ0osvvqgZM2boueeeU2pq6jU8HAAA0BN06XtQ6urq5PP5lJWV5exzu93KyMhQVVWVJKmqqkrx8fFOnEhSVlaWIiMjtXPnzguet62tTYFAIGgDAAA9V5cGis/nkyQlJycH7U9OTnaO+Xw+JSUlBR2Pjo5WQkKCM+ZcZWVlcrvdzpaWltaV0wYAAJbpFp/iKS0tld/vd7bDhw+He0oAACCEujRQPB6PJKmhoSFof0NDg3PM4/GosbEx6Hh7e7uampqcMeeKi4uTy+UK2gAAQM/VpYEybNgweTweVVRUOPsCgYB27twpr9crSfJ6vWpublZ1dbUzZvPmzero6FBGRkZXTgcAAHRTnf4UT2trqw4ePOjcrqurU01NjRISEjR48GAtXrxYv/jFLzRq1CgNGzZMP/vZz5SamqpZs2ZJksaMGaPc3FzNnz9fq1at0unTp1VcXKzZs2fzCR4AACDpKgJl9+7d+va3v+3cLikpkSTNnTtXa9as0aOPPqrjx49rwYIFam5u1h133KFNmzbphhtucO6zdu1aFRcXKzMzU5GRkSooKNALL7zQBQ8HAAD0BBHGGBPuSXRWIBCQ2+2W3+/n/SgArDB02dvhnkKnff5MfringF6mMz+/u8WneAAAQO9CoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsE6XB8qTTz6piIiIoG306NHO8ZMnT6qoqEgDBgxQv379VFBQoIaGhq6eBgAA6MZC8gzK1772NR09etTZtm/f7hx76KGH9NZbb+n1119XZWWljhw5orvuuisU0wAAAN1UdEhOGh0tj8dz3n6/368//OEPWrdunb7zne9IklavXq0xY8Zox44dmjp1aiimAwAAupmQPIPy2WefKTU1VcOHD1dhYaHq6+slSdXV1Tp9+rSysrKcsaNHj9bgwYNVVVV10fO1tbUpEAgEbQAAoOfq8kDJyMjQmjVrtGnTJq1cuVJ1dXX65je/qZaWFvl8PsXGxio+Pj7oPsnJyfL5fBc9Z1lZmdxut7OlpaV19bQBAIBFuvwlnry8POfr8ePHKyMjQ0OGDNGf//xn9enT56rOWVpaqpKSEud2IBAgUgAA6MFC/jHj+Ph43XzzzTp48KA8Ho9OnTql5ubmoDENDQ0XfM/KWXFxcXK5XEEbAADouUIeKK2trTp06JBSUlI0adIkxcTEqKKiwjleW1ur+vp6eb3eUE8FAAB0E13+Es8jjzyimTNnasiQITpy5IieeOIJRUVFac6cOXK73Zo3b55KSkqUkJAgl8ulBx54QF6vl0/wAAAAR5cHyhdffKE5c+bo2LFjGjhwoO644w7t2LFDAwcOlCQ9//zzioyMVEFBgdra2pSTk6OXX365q6cBAAC6sQhjjAn3JDorEAjI7XbL7/fzfhQAVhi67O1wT6HTPn8mP9xTQC/TmZ/f/C0eAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFgnOtwTAIDraeiyt8M9BQBXgGdQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGCd6HBPAAAQHkOXvR2yc3/+TH7Izo3egWdQAACAdcIaKC+99JKGDh2qG264QRkZGfroo4/COR0AAGCJsL3E89prr6mkpESrVq1SRkaGVqxYoZycHNXW1iopKSlc0wIAdIFQvXzES0e9R4QxxoTjG2dkZGjKlCn67W9/K0nq6OhQWlqaHnjgAS1btuyS9w0EAnK73fL7/XK5XNdjugB6iFC+7wLdW6jih/f6/Fdnfn6H5RmUU6dOqbq6WqWlpc6+yMhIZWVlqaqq6rzxbW1tamtrc277/X5JXz3QUBj3xN9Cct79T+WE5LzApYTqepa65zXd0XYi3FOApUL1MyWU19zgh14P2blD8e/77BpfyXMjYQmUf//73zpz5oySk5OD9icnJ+vTTz89b3xZWZmeeuqp8/anpaWFbI6h4F4R7hkAXYtrGj0J13OwUK5HS0uL3G73Jcd0i48Zl5aWqqSkxLnd0dGhpqYmDRgwQBEREWGcWWgFAgGlpaXp8OHDvJR1CazTlWOtrgzrdGVYpyvDOv2XMUYtLS1KTU297NiwBEpiYqKioqLU0NAQtL+hoUEej+e88XFxcYqLiwvaFx8fH8opWsXlcvX6i/pKsE5XjrW6MqzTlWGdrgzr9JXLPXNyVlg+ZhwbG6tJkyapoqLC2dfR0aGKigp5vd5wTAkAAFgkbC/xlJSUaO7cuZo8ebK+/vWva8WKFTp+/Ljuv//+cE0JAABYImyB8sMf/lBffvmlli9fLp/Pp1tvvVWbNm06742zvVlcXJyeeOKJ817eQjDW6cqxVleGdboyrNOVYZ2uTth+DwoAAMDF8Ld4AACAdQgUAABgHQIFAABYh0ABAADWIVDCYNu2bZo5c6ZSU1MVERGhDRs2BB2/7777FBEREbTl5uYGjWlqalJhYaFcLpfi4+M1b948tba2XsdHEVplZWWaMmWK+vfvr6SkJM2aNUu1tbVBY06ePKmioiINGDBA/fr1U0FBwXm//K++vl75+fnq27evkpKStGTJErW3t1/PhxJSV7JO06dPP+96WrhwYdCYnr5OkrRy5UqNHz/e+WVZXq9X7777rnOc6+krl1snrqcLe+aZZxQREaHFixc7+7imrpHBdffOO++Yn/70p+aNN94wksz69euDjs+dO9fk5uaao0ePOltTU1PQmNzcXDNhwgSzY8cO88EHH5iRI0eaOXPmXMdHEVo5OTlm9erVZv/+/aampsbMmDHDDB482LS2tjpjFi5caNLS0kxFRYXZvXu3mTp1qvnGN77hHG9vbzfjxo0zWVlZZs+ePeadd94xiYmJprS0NBwPKSSuZJ2+9a1vmfnz5wddT36/3zneG9bJGGP++te/mrffftv84x//MLW1teaxxx4zMTExZv/+/cYYrqezLrdOXE/n++ijj8zQoUPN+PHjzYMPPujs55q6NgRKmF0sUO68886L3ufjjz82ksyuXbucfe+++66JiIgw//rXv0I00/BqbGw0kkxlZaUxxpjm5mYTExNjXn/9dWfMJ598YiSZqqoqY8xXIRgZGWl8Pp8zZuXKlcblcpm2trbr+wCuk3PXyZivfqD873+a5+qN63TWTTfdZH7/+99zPV3G2XUyhuvpXC0tLWbUqFGmvLw8aG24pq4dL/FYauvWrUpKStItt9yiRYsW6dixY86xqqoqxcfHa/Lkyc6+rKwsRUZGaufOneGYbsj5/X5JUkJCgiSpurpap0+fVlZWljNm9OjRGjx4sKqqqiR9tU7p6elBv/wvJydHgUBABw4cuI6zv37OXaez1q5dq8TERI0bN06lpaU6ceK/f/69N67TmTNn9Oqrr+r48ePyer1cTxdx7jqdxfX0X0VFRcrPzw+6diT+j+oK3eKvGfc2ubm5uuuuuzRs2DAdOnRIjz32mPLy8lRVVaWoqCj5fD4lJSUF3Sc6OloJCQny+XxhmnXodHR0aPHixbr99ts1btw4SZLP51NsbOx5fzQyOTnZWQOfz3febyY+e7u3rJMk3X333RoyZIhSU1O1d+9eLV26VLW1tXrjjTck9a512rdvn7xer06ePKl+/fpp/fr1Gjt2rGpqarie/sfF1knievpfr776qv7+979r165d5x3j/6hrR6BYaPbs2c7X6enpGj9+vEaMGKGtW7cqMzMzjDMLj6KiIu3fv1/bt28P91SsdrF1WrBggfN1enq6UlJSlJmZqUOHDmnEiBHXe5phdcstt6impkZ+v19/+ctfNHfuXFVWVoZ7Wta52DqNHTuW6+n/HT58WA8++KDKy8t1ww03hHs6PRIv8XQDw4cPV2Jiog4ePChJ8ng8amxsDBrT3t6upqYmeTyecEwxZIqLi7Vx40Zt2bJFgwYNcvZ7PB6dOnVKzc3NQeMbGhqcNfB4POe9Y/7s7d6yTheSkZEhSUHXU29Zp9jYWI0cOVKTJk1SWVmZJkyYoN/85jdcT+e42DpdSG+9nqqrq9XY2KjbbrtN0dHRio6OVmVlpV544QVFR0crOTmZa+oaESjdwBdffKFjx44pJSVFkuT1etXc3Kzq6mpnzObNm9XR0eH8Z9HdGWNUXFys9evXa/PmzRo2bFjQ8UmTJikmJkYVFRXOvtraWtXX1zuvlXu9Xu3bty8o5srLy+VyuZynq7u7y63ThdTU1EhS0PXU09fpYjo6OtTW1sb1dBln1+lCeuv1lJmZqX379qmmpsbZJk+erMLCQudrrqlrFO536fZGLS0tZs+ePWbPnj1Gkvn1r39t9uzZY/75z3+alpYW88gjj5iqqipTV1dn3n//fXPbbbeZUaNGmZMnTzrnyM3NNRMnTjQ7d+4027dvN6NGjepRHzNetGiRcbvdZuvWrUEfZzxx4oQzZuHChWbw4MFm8+bNZvfu3cbr9Rqv1+scP/sRvuzsbFNTU2M2bdpkBg4c2KM+wne5dTp48KB5+umnze7du01dXZ158803zfDhw820adOcc/SGdTLGmGXLlpnKykpTV1dn9u7da5YtW2YiIiLMe++9Z4zhejrrUuvE9XRp537CiWvq2hAoYbBlyxYj6bxt7ty55sSJEyY7O9sMHDjQxMTEmCFDhpj58+cHfQzNGGOOHTtm5syZY/r162dcLpe5//77TUtLS5geUde70PpIMqtXr3bG/Oc//zE/+clPzE033WT69u1rvv/975ujR48Gnefzzz83eXl5pk+fPiYxMdE8/PDD5vTp09f50YTO5dapvr7eTJs2zSQkJJi4uDgzcuRIs2TJkqDfW2FMz18nY4z58Y9/bIYMGWJiY2PNwIEDTWZmphMnxnA9nXWpdeJ6urRzA4Vr6tpEGGPM9X7WBgAA4FJ4DwoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6/weHXP7+RP4iiAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) for s in seqs], bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  7.,   2.,   0.,   1.,   4.,   4.,   2.,   0.,   1.,   0.,  78.,\n",
       "        400.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   1.]),\n",
       " array([  14.  ,   41.08,   68.16,   95.24,  122.32,  149.4 ,  176.48,\n",
       "         203.56,  230.64,  257.72,  284.8 ,  311.88,  338.96,  366.04,\n",
       "         393.12,  420.2 ,  447.28,  474.36,  501.44,  528.52,  555.6 ,\n",
       "         582.68,  609.76,  636.84,  663.92,  691.  ,  718.08,  745.16,\n",
       "         772.24,  799.32,  826.4 ,  853.48,  880.56,  907.64,  934.72,\n",
       "         961.8 ,  988.88, 1015.96, 1043.04, 1070.12, 1097.2 , 1124.28,\n",
       "        1151.36, 1178.44, 1205.52, 1232.6 , 1259.68, 1286.76, 1313.84,\n",
       "        1340.92, 1368.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.hist([len(s) for s in generated_sequences], bins=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
